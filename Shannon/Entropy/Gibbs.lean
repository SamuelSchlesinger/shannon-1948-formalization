import Shannon.Entropy.Final

/-!
# Shannon.Entropy.Gibbs

Gibbs inequality and single-variable entropy bounds.

The Gibbs inequality (`∑ pᵢ log(qᵢ/pᵢ) ≤ 0`) is the analytical workhorse for
deriving the properties of Shannon entropy listed in Section 6 of Shannon (1948).
It follows from `log x ≤ x - 1` and the fact that probability masses sum to one.

We also connect `entropyNat` to Mathlib's `Real.negMulLog`, giving access to
Mathlib's concavity infrastructure for later proofs.

## Main results

- `entropyNat_eq_sum_negMulLog`: bridge between `entropyNat` and `Real.negMulLog`
- `gibbs_inequality`: `∑ pᵢ log(qᵢ/pᵢ) ≤ 0`
- `entropyNat_nonneg`: `H(p) ≥ 0`
- `entropyNat_uniformPNat`: `H(uniform n) = log n`
- `entropyNat_le_log_card`: `H(p) ≤ log |α|`
-/
namespace Shannon

noncomputable section
open Finset Real

/-! ## Bridge to negMulLog -/

/-- `entropyNat p = ∑ a, negMulLog (p a)`, connecting our definition to Mathlib's
`Real.negMulLog` which carries concavity and differentiability lemmas. -/
lemma entropyNat_eq_sum_negMulLog {α : Type} [Fintype α] (p : ProbDist α) :
    entropyNat p = ∑ a, Real.negMulLog (p a) := by
  unfold entropyNat Real.negMulLog
  simp [Finset.sum_neg_distrib, neg_mul]

/-! ## Gibbs inequality -/

/-- **Gibbs inequality**: for probability distributions `p` and `q` where `q` covers
the support of `p`, we have `∑ pᵢ log(qᵢ/pᵢ) ≤ 0`. Equivalently, the
Kullback-Leibler divergence `D(p ‖ q) ≥ 0`.

The proof uses `log x ≤ x - 1` on each ratio `qᵢ/pᵢ`, then telescopes via
`∑ qᵢ = ∑ pᵢ = 1`. -/
theorem gibbs_inequality {α : Type} [Fintype α]
    (p q : ProbDist α) (hsupp : ∀ a, 0 < p a → 0 < q a) :
    ∑ a, p a * Real.log (q a / p a) ≤ 0 := by
  have key : ∀ a, p a * Real.log (q a / p a) ≤ q a - p a := by
    intro a
    by_cases hp : p a = 0
    · simp [hp, prob_nonneg q a]
    · have hpa : 0 < p a := lt_of_le_of_ne (prob_nonneg p a) (Ne.symm hp)
      have hqa : 0 < q a := hsupp a hpa
      calc p a * Real.log (q a / p a)
          ≤ p a * (q a / p a - 1) :=
            mul_le_mul_of_nonneg_left (Real.log_le_sub_one_of_pos (div_pos hqa hpa)) hpa.le
        _ = q a - p a := by field_simp
  calc ∑ a, p a * Real.log (q a / p a)
      ≤ ∑ a, (q a - p a) := Finset.sum_le_sum (fun a _ => key a)
    _ = (∑ a, q a) - (∑ a, p a) := by
        simp_rw [sub_eq_add_neg]; rw [Finset.sum_add_distrib, Finset.sum_neg_distrib]
    _ = 0 := by rw [prob_sum_eq_one q, prob_sum_eq_one p, sub_self]

/-! ## Single-variable entropy bounds -/

/-- Entropy is nonnegative: each `negMulLog(pᵢ) ≥ 0` for `pᵢ ∈ [0, 1]`. -/
theorem entropyNat_nonneg {α : Type} [Fintype α] (p : ProbDist α) :
    0 ≤ entropyNat p := by
  rw [entropyNat_eq_sum_negMulLog]
  exact Finset.sum_nonneg fun a _ => Real.negMulLog_nonneg (prob_nonneg p a) (prob_le_one p a)

/-- Entropy of the uniform distribution on `n` outcomes equals `log n`. -/
theorem entropyNat_uniformPNat (n : ℕ+) :
    entropyNat (uniformPNat n) = Real.log n := by
  have hn_pos : (0 : ℝ) < n := by exact_mod_cast n.2
  have hn_ne : (n : ℝ) ≠ 0 := ne_of_gt hn_pos
  rw [entropyNat_eq_sum_negMulLog]
  have hval : ∀ a : Fin n, (uniformPNat n : Fin n → ℝ) a = 1 / (n : ℝ) := fun _ => rfl
  simp_rw [hval, Real.negMulLog, Finset.sum_const, Finset.card_univ, Fintype.card_fin]
  rw [Real.log_div one_ne_zero hn_ne, Real.log_one, zero_sub]
  simp [nsmul_eq_mul]

/-- Entropy is at most `log |α|`, with equality at the uniform distribution.
The proof applies `gibbs_inequality` with `q = uniform`. -/
theorem entropyNat_le_log_card {α : Type} [Fintype α] [Nonempty α]
    (p : ProbDist α) :
    entropyNat p ≤ Real.log (Fintype.card α) := by
  have hcard_pos : (0 : ℝ) < Fintype.card α := by exact_mod_cast Fintype.card_pos (α := α)
  have hcard_ne : (Fintype.card α : ℝ) ≠ 0 := ne_of_gt hcard_pos
  let q : ProbDist α := ⟨fun _ => 1 / (Fintype.card α : ℝ), by
    constructor
    · intro _; positivity
    · simp [Finset.card_univ, hcard_ne]⟩
  have hq_val : ∀ a, q a = 1 / (Fintype.card α : ℝ) := fun _ => rfl
  have hsupp : ∀ a, 0 < p a → 0 < q a := fun a _ => by rw [hq_val]; positivity
  have hgibbs := gibbs_inequality p q hsupp
  suffices h : ∑ a, p a * Real.log (q a / p a) =
      entropyNat p - Real.log (Fintype.card α) by linarith
  have hterm : ∀ a, p a * Real.log (q a / p a) =
      p a * Real.log (q a) - p a * Real.log (p a) := by
    intro a
    by_cases hp : p a = 0
    · simp [hp]
    · have hpa : 0 < p a := lt_of_le_of_ne (prob_nonneg p a) (Ne.symm hp)
      rw [Real.log_div (ne_of_gt (hsupp a hpa)) (ne_of_gt hpa), mul_sub]
  simp_rw [hterm, sub_eq_add_neg]
  rw [Finset.sum_add_distrib]
  have hlogq : ∑ a, p a * Real.log (q a) = -Real.log (Fintype.card α) := by
    simp_rw [hq_val, Real.log_div one_ne_zero hcard_ne, Real.log_one, zero_sub]
    rw [← Finset.sum_mul, prob_sum_eq_one p, one_mul]
  rw [hlogq, Finset.sum_neg_distrib]
  unfold entropyNat; ring

end

end Shannon
